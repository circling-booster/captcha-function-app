import azure.functions as func

import json
import logging
import base64
from pathlib import Path
import torch
import torch.nn as nn
from PIL import Image
import numpy as np
import string
import io
import time
from datetime import datetime

# ==================== ÏÑ§Ï†ï ====================

NUM_CLASSES = 26
BLANK_LABEL = 26
ALPHABETS = string.ascii_uppercase
IDX_TO_CHAR = {i: c for i, c in enumerate(ALPHABETS)}

# Î™®Îç∏Î≥Ñ Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞ ÏÑ§Ï†ï
MODEL_CONFIGS = {
    "melon": {"width": 230, "height": 70, "model_file": "model_melon.pt"},
    "nol": {"width": 210, "height": 70, "model_file": "model_nol.pt"}
}

logger = logging.getLogger("InferenceFunction")
logger.setLevel(logging.INFO)


# ==================== Î™®Îç∏ ====================

class CRNN(nn.Module):
    """CNN-RNN-CTC Í∏∞Î∞ò Ï∫°Ï∞® Ïù∏Ïãù Î™®Îç∏"""

    def __init__(self, img_h, num_classes, rnn_hidden_size=256, rnn_layers=2, rnn_dropout=0.3):
        super().__init__()

        self.cnn = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2),

            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2),

            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.MaxPool2d((2, 2), (2, 2)),
        )

        conv_output_h = img_h // 8
        self.rnn_input_size = 128 * conv_output_h

        self.rnn = nn.LSTM(
            input_size=self.rnn_input_size,
            hidden_size=rnn_hidden_size,
            num_layers=rnn_layers,
            dropout=rnn_dropout,
            bidirectional=True,
            batch_first=True,
        )

        self.fc = nn.Linear(rnn_hidden_size * 2, num_classes + 1)

    def forward(self, x):
        x = self.cnn(x)
        b, c, h, w = x.size()
        x = x.permute(0, 3, 1, 2)
        x = x.contiguous().view(b, w, c * h)
        x, _ = self.rnn(x)
        x = self.fc(x)
        x = x.permute(1, 0, 2)
        return x


# ==================== Î™®Îç∏ Í¥ÄÎ¶¨ ====================

class ModelManager:
    """Î™®Îç∏ Î°úÎî© Î∞è Í¥ÄÎ¶¨ (Î™®Îç∏Î≥Ñ Ï∫êÏã±)"""

    _models = {}
    _device = None
    _last_load_time = {}

    @classmethod
    def get_model(cls, model_type: str):
        """Î™®Îç∏ ÌÉÄÏûÖÏóê Îî∞Îùº Î™®Îç∏ Î°úÎìú ÎòêÎäî Ï∫êÏãúÏóêÏÑú Î∞òÌôò"""

        # Ïú†Ìö®Ìïú Î™®Îç∏ ÌÉÄÏûÖ ÌôïÏù∏
        if model_type not in MODEL_CONFIGS:
            raise ValueError(f"Ïú†Ìö®ÌïòÏßÄ ÏïäÏùÄ Î™®Îç∏ ÌÉÄÏûÖ: {model_type}. ÏßÄÏõêÎêòÎäî ÌÉÄÏûÖ: {list(MODEL_CONFIGS.keys())}")

        if model_type not in cls._models:
            cls.load_model(model_type)

        return cls._models[model_type]

    @classmethod
    def get_device(cls):
        """ÎîîÎ∞îÏù¥Ïä§ Î∞òÌôò (CUDA ÎòêÎäî CPU)"""
        if cls._device is None:
            cls._device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return cls._device

    @classmethod
    def load_model(cls, model_type: str):
        """Î™®Îç∏ Î°úÎìú"""
        try:
            config = MODEL_CONFIGS[model_type]
            model_path = Path(__file__).parent / config["model_file"]

            if not model_path.exists():
                raise FileNotFoundError(f"Î™®Îç∏ ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§: {model_path}")

            device = cls.get_device()

            # Ïù¥ÎØ∏ÏßÄ ÎÜíÏù¥Î•º Í∏∞Î∞òÏúºÎ°ú Î™®Îç∏ ÏÉùÏÑ±
            model = CRNN(config["height"], NUM_CLASSES).to(device)
            model.load_state_dict(torch.load(model_path, map_location=device))
            model.eval()

            cls._models[model_type] = model
            cls._last_load_time[model_type] = datetime.now()

            logger.info(f"‚úì Î™®Îç∏ Î°úÎìú ÏôÑÎ£å [{model_type}]: {model_path}")
            logger.info(f"  - Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞: {config['width']}x{config['height']}")
            logger.info(f"  - ÎîîÎ∞îÏù¥Ïä§: {device}")

        except Exception as e:
            logger.error(f"‚ùå Î™®Îç∏ Î°úÎìú Ïã§Ìå® [{model_type}]: {e}")
            raise


# ==================== Ïù¥ÎØ∏ÏßÄ Ï≤òÎ¶¨ ====================

def preprocess_image(image_bytes, model_type: str) -> torch.Tensor:
    """Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤òÎ¶¨ (Î™®Îç∏ ÌÉÄÏûÖÏóê Îî∞Î•∏ ÌÅ¨Í∏∞ Ï°∞Ï†ï)"""
    try:
        config = MODEL_CONFIGS[model_type]
        image_width = config["width"]
        image_height = config["height"]

        # Base64Î°ú Ïù∏ÏΩîÎî©Îêú Í≤ΩÏö∞ ÎîîÏΩîÎî©
        if isinstance(image_bytes, str):
            try:
                image_bytes = base64.b64decode(image_bytes)
            except Exception:
                pass  # Ïù¥ÎØ∏ Î∞îÏù¥ÎÑàÎ¶¨ Îç∞Ïù¥ÌÑ∞Ïù∏ Í≤ΩÏö∞

        image = Image.open(io.BytesIO(image_bytes)).convert("L")
        image = image.resize((image_width, image_height), Image.BILINEAR)

        image_np = np.array(image, dtype=np.float32)
        image_np = image_np / 255.0

        image_tensor = torch.from_numpy(image_np).unsqueeze(0)
        image_tensor = image_tensor.unsqueeze(0)

        logger.info(f"‚úì Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤òÎ¶¨ ÏôÑÎ£å [{model_type}]: tensor shape {image_tensor.shape}")

        return image_tensor

    except Exception as e:
        logger.error(f"‚ùå Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤òÎ¶¨ Ïã§Ìå®: {e}")
        raise


# ==================== Ï∂îÎ°† ====================

def ctc_decode(predictions):
    """CTC ÎîîÏΩîÎî©"""
    preds = predictions.argmax(dim=2)
    preds = preds.cpu().numpy().transpose(1, 0)

    decoded = []
    for p in preds:
        prev = -1
        seq = []
        for idx in p:
            if idx != prev and idx != BLANK_LABEL:
                seq.append(idx)
            prev = idx
        decoded.append("".join([IDX_TO_CHAR[i] for i in seq]))

    return decoded


def infer(image_tensor: torch.Tensor, model, device):
    """Ï∂îÎ°† ÏàòÌñâ"""
    try:
        image_tensor = image_tensor.to(device)

        with torch.no_grad():
            logits = model(image_tensor)
            predictions = ctc_decode(logits)

        return predictions if predictions else [""]

    except Exception as e:
        logger.error(f"‚ùå Ï∂îÎ°† Ïã§Ìå®: {e}")
        raise


# ==================== HTTP Trigger ====================

app = func.FunctionApp()


@app.route(route="InferenceHttpTrigger", methods=["POST"], auth_level=func.AuthLevel.ANONYMOUS)
def infer_captcha(req: func.HttpRequest) -> func.HttpResponse:
    """
    Ïù¥ÎØ∏ÏßÄÎ•º Base64 ÎòêÎäî Data URL ÌòïÏãù JSON POSTÎ°ú Î∞õÏïÑ Ï∫°Ï∞® Ïù∏Ïãù ÏàòÌñâ

    ÏöîÏ≤≠ ÌòïÏãù:
    {
        "image": "data:image/png;base64,iVBORw0KGgo..." ÎòêÎäî "iVBORw0KGgo...",
        "url": "melon" ÎòêÎäî "nol"
    }
    """
    start_time = time.time()

    try:
        logger.info("üì• Ï∂îÎ°† ÏöîÏ≤≠ ÏàòÏã†")

        # JSON Î∞îÎîî ÌååÏã±
        try:
            req_body = req.get_json()
        except ValueError:
            logger.warning("‚ùå JSON ÌååÏã± Ïã§Ìå®")
            return func.HttpResponse(
                json.dumps({
                    "status": "error",
                    "message": "Ïú†Ìö®Ìïú JSON ÌòïÏãùÏù¥ ÏïÑÎãôÎãàÎã§"
                }),
                status_code=400,
                mimetype="application/json"
            )

        # ÌïÑÏàò ÌååÎùºÎØ∏ÌÑ∞ ÌôïÏù∏
        if "image" not in req_body:
            logger.warning("‚ùå 'image' ÌïÑÎìúÍ∞Ä ÏóÜÏäµÎãàÎã§")
            return func.HttpResponse(
                json.dumps({
                    "status": "error",
                    "message": "'image' ÌïÑÎìúÍ∞Ä ÌïÑÏöîÌï©ÎãàÎã§ (base64 ÌòïÏãù ÎòêÎäî Data URL)"
                }),
                status_code=400,
                mimetype="application/json"
            )

        if "url" not in req_body:
            logger.warning("‚ùå 'url' ÌïÑÎìúÍ∞Ä ÏóÜÏäµÎãàÎã§")
            return func.HttpResponse(
                json.dumps({
                    "status": "error",
                    "message": "'url' ÌïÑÎìúÍ∞Ä ÌïÑÏöîÌï©ÎãàÎã§ ('melon' ÎòêÎäî 'nol')"
                }),
                status_code=400,
                mimetype="application/json"
            )

        image_data = req_body["image"]
        model_type = req_body["url"]

        # Î™®Îç∏ ÌÉÄÏûÖ Ïú†Ìö®ÏÑ± ÌôïÏù∏
        if model_type not in MODEL_CONFIGS:
            logger.warning(f"‚ùå Ïú†Ìö®ÌïòÏßÄ ÏïäÏùÄ Î™®Îç∏ ÌÉÄÏûÖ: {model_type}")
            return func.HttpResponse(
                json.dumps({
                    "status": "error",
                    "message": f"Ïú†Ìö®ÌïòÏßÄ ÏïäÏùÄ 'url' Í∞íÏûÖÎãàÎã§. ÏßÄÏõêÎêòÎäî Í∞í: {list(MODEL_CONFIGS.keys())}"
                }),
                status_code=400,
                mimetype="application/json"
            )

        # Base64 Ïù¥ÎØ∏ÏßÄ Îç∞Ïù¥ÌÑ∞ Í≤ÄÏ¶ù
        if not image_data:
            logger.warning("‚ùå Ïù¥ÎØ∏ÏßÄ Îç∞Ïù¥ÌÑ∞Í∞Ä ÎπÑÏñ¥ÏûàÏäµÎãàÎã§")
            return func.HttpResponse(
                json.dumps({
                    "status": "error",
                    "message": "Ïù¥ÎØ∏ÏßÄ Îç∞Ïù¥ÌÑ∞Í∞Ä ÎπÑÏñ¥ÏûàÏäµÎãàÎã§"
                }),
                status_code=400,
                mimetype="application/json"
            )

        logger.info(f"üì§ ÏöîÏ≤≠ Ï†ïÎ≥¥ - Î™®Îç∏: {model_type}, Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞: {len(image_data)} chars")

        # Base64 ÎîîÏΩîÎî© (Data URL ÌòïÏãù ÏßÄÏõê)
        try:
            # Data URL ÌòïÏãù Ï≤òÎ¶¨ (Ïòà: data:image/png;base64,iVBORw0KGgo...)
            if isinstance(image_data, str) and image_data.startswith("data:"):
                # Data URLÏóêÏÑú base64 Î∂ÄÎ∂ÑÎßå Ï∂îÏ∂ú
                if ";base64," in image_data:
                    extracted_data = image_data.split(";base64,")[1]
                    logger.info(f"‚úì Data URL ÌòïÏãùÏóêÏÑú base64 Ï∂îÏ∂ú ÏôÑÎ£å")
                    image_data = extracted_data
                else:
                    logger.warning("‚ùå Data URL ÌòïÏãùÏù¥ÏßÄÎßå ;base64, Íµ¨Î∂ÑÏûêÍ∞Ä ÏóÜÏäµÎãàÎã§")
                    return func.HttpResponse(
                        json.dumps({
                            "status": "error",
                            "message": "Data URL ÌòïÏãùÏù¥ Ïò¨Î∞îÎ•¥ÏßÄ ÏïäÏäµÎãàÎã§. 'data:image/...;base64,...' ÌòïÏãùÏù¥Ïñ¥Ïïº Ìï©ÎãàÎã§"
                        }),
                        status_code=400,
                        mimetype="application/json"
                    )

            image_bytes = base64.b64decode(image_data)
            logger.info(f"‚úì Base64 ÎîîÏΩîÎî© ÏôÑÎ£å: {len(image_bytes)} bytes")
        except Exception as e:
            logger.warning(f"‚ùå Base64 ÎîîÏΩîÎî© Ïã§Ìå®: {e}")
            return func.HttpResponse(
                json.dumps({
                    "status": "error",
                    "message": "Base64 ÎîîÏΩîÎî© Ïã§Ìå®. Ïú†Ìö®Ìïú Base64 ÌòïÏãù ÎòêÎäî Data URL ÌòïÏãù(data:image/...;base64,...)Ïù∏ÏßÄ ÌôïÏù∏ÌïòÏÑ∏Ïöî"
                }),
                status_code=400,
                mimetype="application/json"
            )

        # Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤òÎ¶¨
        logger.info(f"üîÑ Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤òÎ¶¨ Ï§ë... [{model_type}]")
        image_tensor = preprocess_image(image_bytes, model_type)
        logger.info(f"‚úì Ïù¥ÎØ∏ÏßÄ ÌÖêÏÑú shape: {image_tensor.shape}")

        # Î™®Îç∏ Î°úÎìú
        logger.info(f"üîÑ Î™®Îç∏ Î°úÎìú Ï§ë... [{model_type}]")
        model = ModelManager.get_model(model_type)
        device = ModelManager.get_device()
        logger.info(f"‚úì Î™®Îç∏ Ï§ÄÎπÑ ÏôÑÎ£å")

        # Ï∂îÎ°† ÏàòÌñâ
        logger.info("üîÑ Ï∂îÎ°† ÏàòÌñâ Ï§ë...")
        predicted_texts = infer(image_tensor, model, device)
        predicted_text = predicted_texts[0] if predicted_texts else ""
        logger.info(f"‚úì Ï∂îÎ°† Í≤∞Í≥º: {predicted_text}")

        # Ïã†Î¢∞ÎèÑ Í≥ÑÏÇ∞
        with torch.no_grad():
            image_tensor_device = image_tensor.to(device)
            logits = model(image_tensor_device)
            probs = torch.softmax(logits, dim=2)
            confidence = float(probs.max().item())

        processing_time_ms = (time.time() - start_time) * 1000
        logger.info(f"‚úÖ Ï∂îÎ°† ÏôÑÎ£å ({processing_time_ms:.1f}ms)")

        response = {
            "status": "success",
            "predicted_text": predicted_text,
            "model_type": model_type,
            "confidence": round(confidence, 4),
            "processing_time_ms": round(processing_time_ms, 1)
        }

        return func.HttpResponse(
            json.dumps(response),
            status_code=200,
            mimetype="application/json"
        )

    except FileNotFoundError as e:
        logger.error(f"‚ùå ÌååÏùº Ïò§Î•ò: {e}")
        return func.HttpResponse(
            json.dumps({
                "status": "error",
                "message": f"Î™®Îç∏ ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§: {e}"
            }),
            status_code=500,
            mimetype="application/json"
        )

    except Exception as e:
        logger.error(f"‚ùå ÏòàÏô∏ Î∞úÏÉù: {e}")
        import traceback
        traceback.print_exc()

        return func.HttpResponse(
            json.dumps({
                "status": "error",
                "message": f"Ï∂îÎ°† Ï≤òÎ¶¨ Ï§ë Ïò§Î•ò Î∞úÏÉù: {str(e)}"
            }),
            status_code=500,
            mimetype="application/json"
        )


@app.route(route="health", methods=["GET"], auth_level=func.AuthLevel.ANONYMOUS)
def health_check(req: func.HttpRequest) -> func.HttpResponse:
    """Ìó¨Ïä§ Ï≤¥ÌÅ¨ ÏóîÎìúÌè¨Ïù∏Ìä∏"""
    try:
        model_status = {}

        for model_type in MODEL_CONFIGS.keys():
            try:
                model = ModelManager.get_model(model_type)
                model_status[model_type] = {
                    "status": "loaded",
                    "last_load_time": str(ModelManager._last_load_time.get(model_type, "N/A"))
                }
            except Exception as e:
                model_status[model_type] = {
                    "status": "not_loaded",
                    "error": str(e)
                }

        device = ModelManager.get_device()

        return func.HttpResponse(
            json.dumps({
                "status": "healthy",
                "device": str(device),
                "models": model_status
            }),
            status_code=200,
            mimetype="application/json"
        )

    except Exception as e:
        return func.HttpResponse(
            json.dumps({
                "status": "unhealthy",
                "error": str(e)
            }),
            status_code=500,
            mimetype="application/json"
        )