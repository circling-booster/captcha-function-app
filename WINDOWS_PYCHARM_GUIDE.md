# Windows 10 + PyCharmì—ì„œ Azure Function App ë°°í¬ ì™„ë²½ ê°€ì´ë“œ
# ë„ë©”ì¸: captcha-inference-app-f0ejcugkgqgvh4e9.koreacentral-01.azurewebsites.net

## ğŸ“‹ ëª©ì°¨

1. [í™˜ê²½ ì¤€ë¹„](#1-í™˜ê²½-ì¤€ë¹„)
2. [PyCharm í”„ë¡œì íŠ¸ ì„¤ì •](#2-pycharm-í”„ë¡œì íŠ¸-ì„¤ì •)
3. [Azure ë„êµ¬ ì„¤ì¹˜](#3-azure-ë„êµ¬-ì„¤ì¹˜)
4. [Function App ì½”ë“œ ì‘ì„±](#4-function-app-ì½”ë“œ-ì‘ì„±)
5. [ë¡œì»¬ í…ŒìŠ¤íŠ¸](#5-ë¡œì»¬-í…ŒìŠ¤íŠ¸)
6. [Azureì— ë°°í¬](#6-azureì—-ë°°í¬)
7. [ë°°í¬ í›„ ê²€ì¦](#7-ë°°í¬-í›„-ê²€ì¦)
8. [API ì‚¬ìš© ê°€ì´ë“œ](#8-api-ì‚¬ìš©-ê°€ì´ë“œ)

---

## 1. í™˜ê²½ ì¤€ë¹„

### 1.1 í•„ìˆ˜ ì†Œí”„íŠ¸ì›¨ì–´ í™•ì¸

**PyCharm í™•ì¸:**
- PyCharm ì—´ê¸°
- File â†’ Settings (ë˜ëŠ” Ctrl+Alt+S)
- Python Interpreterì—ì„œ Python 3.11+ ì„¤ì¹˜ í™•ì¸

**Windows ì»¤ë§¨ë“œ í™•ì¸:**
- `Win + R` ì…ë ¥ í›„ `cmd` ì‹¤í–‰
- `python --version` ì…ë ¥ â†’ Python 3.11+ í‘œì‹œ í™•ì¸
- `pip --version` ì…ë ¥ í™•ì¸

### 1.2 í•„ìˆ˜ í”„ë¡œê·¸ë¨ ì„¤ì¹˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

```
â˜ Python 3.11+ ì„¤ì¹˜ë¨
â˜ pip ìµœì‹  ë²„ì „
â˜ PyCharm ì„¤ì¹˜ë¨
â˜ Git ì„¤ì¹˜ë¨ (ì„ íƒì‚¬í•­)
```

---

## 2. PyCharm í”„ë¡œì íŠ¸ ì„¤ì •

### 2.1 ìƒˆ í”„ë¡œì íŠ¸ ìƒì„±

**Step 1: PyCharm ë©”ì¸ í™”ë©´**
- File â†’ New Project

**Step 2: í”„ë¡œì íŠ¸ ì„¤ì •**
```
í”„ë¡œì íŠ¸ëª…: captcha-inference-app
ê²½ë¡œ: C:\Users\{YourUsername}\captcha-inference-app
```

**Step 3: Python ì¸í„°í”„ë¦¬í„° ì„ íƒ**
- New environment using Virtualenv ì„ íƒ
- Location: ìë™ ì„¤ì •
- Python 3.11 ì„ íƒ
- Create í´ë¦­

### 2.2 PyCharm ì½˜ì†”ì—ì„œ í™•ì¸

PyCharm í•˜ë‹¨ì˜ Terminal íƒ­ ì—´ê¸°:

```bash
# ê°€ìƒí™˜ê²½ í™œì„±í™” í™•ì¸ (prompt ì•ì— (venv) í‘œì‹œ)
# Python ë²„ì „ í™•ì¸
python --version
# ì¶œë ¥: Python 3.11.x
```

---

## 3. Azure ë„êµ¬ ì„¤ì¹˜

### 3.1 Azure CLI ì„¤ì¹˜

**ë°©ë²• 1: ì§ì ‘ ì„¤ì¹˜ (ê¶Œì¥)**

1. https://learn.microsoft.com/en-us/cli/azure/install-azure-cli-windows ë°©ë¬¸
2. MSI ì¸ìŠ¤í†¨ëŸ¬ ë‹¤ìš´ë¡œë“œ
3. ì‹¤í–‰ ë° ì„¤ì¹˜
4. ì™„ë£Œ í›„ ì¬ë¶€íŒ…

**ì„¤ì¹˜ í™•ì¸:**

PyCharm Terminalì—ì„œ:
```bash
az --version
# ì¶œë ¥ ì˜ˆ:
# azure-cli                    2.56.0
# core                         2.56.0
```

### 3.2 Azure Functions Core Tools ì„¤ì¹˜

**PowerShellì„ ê´€ë¦¬ìë¡œ ì‹¤í–‰:**

```powershell
choco install azure-functions-core-tools-4
```

(Chocolatey ë¯¸ì„¤ì¹˜ ì‹œ: https://chocolatey.org/install ì°¸ê³ )

**ë˜ëŠ” npm ì‚¬ìš©:**

```bash
npm install -g azure-functions-core-tools@4 --unsafe-perm true
```

**ì„¤ì¹˜ í™•ì¸:**

```bash
func --version
# ì¶œë ¥: 4.x.x
```

### 3.3 í•„ìš”í•œ Python íŒ¨í‚¤ì§€ ì„¤ì¹˜

PyCharm Terminalì—ì„œ:

```bash
pip install azure-functions azure-storage-blob torch pillow numpy requests
```

ì„¤ì¹˜ ì§„í–‰ë¥ :
```
Collecting azure-functions
Downloading ... 
...
Successfully installed azure-functions-1.20.0
...
Successfully installed all packages
```

---

## 4. Function App ì½”ë“œ ì‘ì„±

### 4.1 í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±

PyCharmì—ì„œ ìƒˆ í´ë” ìƒì„±:

**Path: captcha-inference-app/**

```
captcha-inference-app/
â”œâ”€â”€ function_app.py          (â­ ë©”ì¸ í•¨ìˆ˜ ì½”ë“œ)
â”œâ”€â”€ requirements.txt         (ì˜ì¡´ì„±)
â”œâ”€â”€ host.json               (ì„¤ì •)
â”œâ”€â”€ local.settings.json     (ë¡œì»¬ ì„¤ì •)
â”œâ”€â”€ model/                  (ëª¨ë¸ íŒŒì¼ í´ë”)
â”‚   â””â”€â”€ model_best.pt      (í•™ìŠµëœ ëª¨ë¸)
â”œâ”€â”€ test_client.py         (í…ŒìŠ¤íŠ¸ í´ë¼ì´ì–¸íŠ¸)
â””â”€â”€ .gitignore             (Git ë¬´ì‹œ íŒŒì¼)
```

### 4.2 ë””ë ‰í† ë¦¬ ìƒì„± (PyCharm)

**Right-click on project root:**
1. New â†’ Directory
   - ì´ë¦„: `model`
   - Create

### 4.3 íŒŒì¼ ìƒì„± ë° ì‘ì„±

#### íŒŒì¼ 1: `requirements.txt`

**Right-click on project:**
1. New â†’ File
2. ì´ë¦„: `requirements.txt`
3. ë‹¤ìŒ ë‚´ìš© ì…ë ¥:

```
torch==2.3.0
azure-functions==1.20.0
azure-storage-blob==12.20.0
azure-identity==1.15.0
pillow==10.1.0
numpy==1.24.3
requests==2.31.0
```

**ì €ì¥: Ctrl+S**

#### íŒŒì¼ 2: `function_app.py`

**Right-click on project:**
1. New â†’ File
2. ì´ë¦„: `function_app.py`
3. ë‹¤ìŒ ì „ì²´ ì½”ë“œ ì…ë ¥:

```python
import azure.functions as func
import json
import logging
from pathlib import Path
import torch
import torch.nn as nn
from PIL import Image
import numpy as np
import string
import io
import time
from datetime import datetime

# ==================== ì„¤ì • ====================
IMAGE_WIDTH = 230
IMAGE_HEIGHT = 70
NUM_CLASSES = 26
BLANK_LABEL = 26
ALPHABETS = string.ascii_uppercase
IDX_TO_CHAR = {i: c for i, c in enumerate(ALPHABETS)}

logger = logging.getLogger("InferenceFunction")
logger.setLevel(logging.INFO)

# ==================== ëª¨ë¸ ====================
class CRNN(nn.Module):
    """CNN-RNN-CTC ê¸°ë°˜ ìº¡ì°¨ ì¸ì‹ ëª¨ë¸"""
    def __init__(self, img_h, num_classes, rnn_hidden_size=256, rnn_layers=2, rnn_dropout=0.3):
        super().__init__()
        self.cnn = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2),
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2),
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.MaxPool2d((2, 2), (2, 2)),
        )
        
        conv_output_h = img_h // 8
        self.rnn_input_size = 128 * conv_output_h
        
        self.rnn = nn.LSTM(
            input_size=self.rnn_input_size,
            hidden_size=rnn_hidden_size,
            num_layers=rnn_layers,
            dropout=rnn_dropout,
            bidirectional=True,
            batch_first=True,
        )
        
        self.fc = nn.Linear(rnn_hidden_size * 2, num_classes + 1)
    
    def forward(self, x):
        x = self.cnn(x)
        b, c, h, w = x.size()
        x = x.permute(0, 3, 1, 2)
        x = x.contiguous().view(b, w, c * h)
        x, _ = self.rnn(x)
        x = self.fc(x)
        x = x.permute(1, 0, 2)
        return x

# ==================== ëª¨ë¸ ê´€ë¦¬ ====================
class ModelManager:
    """ëª¨ë¸ ë¡œë”© ë° ê´€ë¦¬"""
    _model = None
    _device = None
    _last_load_time = None
    
    @classmethod
    def get_model(cls):
        if cls._model is None:
            cls.load_model()
        return cls._model
    
    @classmethod
    def get_device(cls):
        if cls._device is None:
            cls._device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        return cls._device
    
    @classmethod
    def load_model(cls):
        try:
            model_path = Path(__file__).parent / "model" / "model_best.pt"
            
            if not model_path.exists():
                raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
            
            device = cls.get_device()
            cls._model = CRNN(IMAGE_HEIGHT, NUM_CLASSES).to(device)
            cls._model.load_state_dict(torch.load(model_path, map_location=device))
            cls._model.eval()
            cls._last_load_time = datetime.now()
            
            logger.info(f"âœ“ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
            logger.info(f"  ë””ë°”ì´ìŠ¤: {device}")
            
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise

# ==================== ì´ë¯¸ì§€ ì²˜ë¦¬ ====================
def preprocess_image(image_bytes) -> torch.Tensor:
    try:
        image = Image.open(io.BytesIO(image_bytes)).convert("L")
        image = image.resize((IMAGE_WIDTH, IMAGE_HEIGHT), Image.BILINEAR)
        image_np = np.array(image, dtype=np.float32)
        image_np = image_np / 255.0
        image_tensor = torch.from_numpy(image_np).unsqueeze(0)
        image_tensor = image_tensor.unsqueeze(0)
        return image_tensor
    except Exception as e:
        logger.error(f"âŒ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        raise

# ==================== ì¶”ë¡  ====================
def ctc_decode(predictions):
    preds = predictions.argmax(dim=2)
    preds = preds.cpu().numpy().transpose(1, 0)
    
    decoded = []
    for p in preds:
        prev = -1
        seq = []
        for idx in p:
            if idx != prev and idx != BLANK_LABEL:
                seq.append(idx)
            prev = idx
        decoded.append("".join([IDX_TO_CHAR[i] for i in seq]))
    
    return decoded

def infer(image_tensor: torch.Tensor, model, device):
    try:
        image_tensor = image_tensor.to(device)
        
        with torch.no_grad():
            logits = model(image_tensor)
            predictions = ctc_decode(logits)
        
        return predictions[0] if predictions else ""
    except Exception as e:
        logger.error(f"âŒ ì¶”ë¡  ì‹¤íŒ¨: {e}")
        raise

# ==================== HTTP Trigger ====================
app = func.FunctionApp()

@app.route(route="InferenceHttpTrigger", methods=["POST"])
def infer_captcha(req: func.HttpRequest) -> func.HttpResponse:
    """ì´ë¯¸ì§€ë¥¼ ë°›ì•„ ìº¡ì°¨ ì¸ì‹ ìˆ˜í–‰"""
    start_time = time.time()
    
    try:
        logger.info("ğŸ“¥ ì¶”ë¡  ìš”ì²­ ìˆ˜ì‹ ")
        
        if "image" not in req.files:
            logger.warning("âŒ 'image' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
            return func.HttpResponse(
                json.dumps({
                    "status": "error",
                    "message": "'image' íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤ (multipart/form-data)"
                }),
                status_code=400,
                mimetype="application/json"
            )
        
        image_file = req.files["image"]
        image_bytes = image_file.read()
        
        if not image_bytes:
            logger.warning("âŒ ì´ë¯¸ì§€ íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
            return func.HttpResponse(
                json.dumps({
                    "status": "error",
                    "message": "ì´ë¯¸ì§€ íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"
                }),
                status_code=400,
                mimetype="application/json"
            )
        
        logger.info(f"ğŸ“¤ ì´ë¯¸ì§€ í¬ê¸°: {len(image_bytes)} bytes")
        
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        logger.info("ğŸ”„ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì¤‘...")
        image_tensor = preprocess_image(image_bytes)
        logger.info(f"âœ“ ì´ë¯¸ì§€ í…ì„œ shape: {image_tensor.shape}")
        
        # ëª¨ë¸ ë¡œë“œ
        logger.info("ğŸ”„ ëª¨ë¸ ë¡œë“œ ì¤‘...")
        model = ModelManager.get_model()
        device = ModelManager.get_device()
        logger.info(f"âœ“ ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ")
        
        # ì¶”ë¡  ìˆ˜í–‰
        logger.info("ğŸ”„ ì¶”ë¡  ìˆ˜í–‰ ì¤‘...")
        predicted_text = infer(image_tensor, model, device)
        logger.info(f"âœ“ ì¶”ë¡  ê²°ê³¼: {predicted_text}")
        
        # ì‹ ë¢°ë„ ê³„ì‚°
        with torch.no_grad():
            image_tensor_device = image_tensor.to(device)
            logits = model(image_tensor_device)
            probs = torch.softmax(logits, dim=2)
            confidence = float(probs.max().item())
        
        processing_time_ms = (time.time() - start_time) * 1000
        
        logger.info(f"âœ… ì¶”ë¡  ì™„ë£Œ ({processing_time_ms:.1f}ms)")
        
        response = {
            "status": "success",
            "predicted_text": predicted_text,
            "confidence": round(confidence, 4),
            "processing_time_ms": round(processing_time_ms, 1)
        }
        
        return func.HttpResponse(
            json.dumps(response),
            status_code=200,
            mimetype="application/json"
        )
    
    except FileNotFoundError as e:
        logger.error(f"âŒ íŒŒì¼ ì˜¤ë¥˜: {e}")
        return func.HttpResponse(
            json.dumps({
                "status": "error",
                "message": f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}"
            }),
            status_code=500,
            mimetype="application/json"
        )
    
    except Exception as e:
        logger.error(f"âŒ ì˜ˆì™¸ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        
        return func.HttpResponse(
            json.dumps({
                "status": "error",
                "message": f"ì¶”ë¡  ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            }),
            status_code=500,
            mimetype="application/json"
        )

@app.route(route="health", methods=["GET"])
def health_check(req: func.HttpRequest) -> func.HttpResponse:
    """í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    try:
        model = ModelManager.get_model()
        device = ModelManager.get_device()
        
        return func.HttpResponse(
            json.dumps({
                "status": "healthy",
                "model_loaded": model is not None,
                "device": str(device),
                "last_load_time": str(ModelManager._last_load_time)
            }),
            status_code=200,
            mimetype="application/json"
        )
    
    except Exception as e:
        return func.HttpResponse(
            json.dumps({
                "status": "unhealthy",
                "error": str(e)
            }),
            status_code=500,
            mimetype="application/json"
        )
```

**ì €ì¥: Ctrl+S**

#### íŒŒì¼ 3: `host.json`

```json
{
  "version": "2.0",
  "logging": {
    "applicationInsights": {
      "samplingSettings": {
        "isEnabled": true,
        "maxTelemetryItemsPerSecond": 20
      }
    }
  },
  "extensionBundle": {
    "id": "Microsoft.Azure.Functions.ExtensionBundle",
    "version": "[4.*, 5.0.0)"
  },
  "functionTimeout": "00:05:00"
}
```

#### íŒŒì¼ 4: `local.settings.json`

```json
{
  "IsEncrypted": false,
  "Values": {
    "AzureWebJobsStorage": "UseDevelopmentStorage=true",
    "FUNCTIONS_WORKER_RUNTIME": "python",
    "AzureWebJobsFeatureFlags": "EnableWorkerIndexing"
  }
}
```

### 4.4 ëª¨ë¸ íŒŒì¼ ë³µì‚¬

**Windows íƒìƒ‰ê¸° ë˜ëŠ” PyCharm:**

1. `model/` í´ë”ì— ì˜¤ë¥¸ìª½ í´ë¦­
2. Open in Explorer
3. í•™ìŠµëœ `model_best.pt` íŒŒì¼ ë³µì‚¬
4. í•´ë‹¹ í´ë”ì— ë¶™ì—¬ë„£ê¸°

ê²°ê³¼:
```
captcha-inference-app/model/model_best.pt âœ“
```

---

## 5. ë¡œì»¬ í…ŒìŠ¤íŠ¸

### 5.1 PyCharm Terminalì—ì„œ ë¡œì»¬ ì‹¤í–‰

```bash
# 1. ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# 2. Azure Functions Core Toolsë¡œ ì‹¤í–‰
func start

# ì¶œë ¥:
# Azure Functions Core Tools
# Found Python version 3.11.x
# ...
# Now listening on: http://0.0.0.0:7071
# Application started. Press Ctrl+C to quit.
```

### 5.2 ë‹¤ë¥¸ Terminalì—ì„œ í…ŒìŠ¤íŠ¸

**ìƒˆ Terminal ì—´ê¸° (Ctrl+Shift+Alt+T ë˜ëŠ” Terminal â†’ New)**

```bash
# í—¬ìŠ¤ ì²´í¬
curl http://localhost:7071/api/health

# ì‘ë‹µ:
# {
#   "status": "healthy",
#   "model_loaded": true,
#   "device": "cpu",
#   "last_load_time": "2024-12-22 15:30:45.123456"
# }
```

**ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸:**

```bash
# test_image.pngê°€ ìˆë‹¤ê³  ê°€ì •
curl -X POST http://localhost:7071/api/InferenceHttpTrigger ^
  -F "image=@test_image.png"

# ì‘ë‹µ:
# {
#   "status": "success",
#   "predicted_text": "ABCDEF",
#   "confidence": 0.9523,
#   "processing_time_ms": 145.2
# }
```

---

## 6. Azureì— ë°°í¬

### 6.1 Azure CLI ë¡œê·¸ì¸

PyCharm Terminal:

```bash
az login
```

**ë¸Œë¼ìš°ì € ìë™ ì—´ë¦¼:**
- Microsoft ê³„ì •ìœ¼ë¡œ ë¡œê·¸ì¸
- ê¶Œí•œ í—ˆê°€
- Terminalì— ì„±ê³µ ë©”ì‹œì§€ ë‚˜íƒ€ë‚¨

### 6.2 ë°°í¬ ì¤€ë¹„

```bash
# Function App ì´ë¦„ í™•ì¸
az functionapp show ^
  --name captcha-inference-app ^
  --resource-group booster-ml ^
  --query "name" ^
  --output tsv

# ì¶œë ¥:
# captcha-inference-app
```

### 6.3 Azureì— ë°°í¬

```bash
func azure functionapp publish captcha-inference-app

# ì§„í–‰ ìƒí™©:
# Getting site publishing info...
# Preparing archive...
# Uploading ... 100%
# Deployment successful
```

**ë°°í¬ ì™„ë£Œ!**

---

## 7. ë°°í¬ í›„ ê²€ì¦

### 7.1 ë°°í¬ëœ í•¨ìˆ˜ URL í™•ì¸

```bash
az functionapp show ^
  --name captcha-inference-app ^
  --resource-group booster-ml ^
  --query "defaultHostName" ^
  --output tsv

# ì¶œë ¥:
# captcha-inference-app-f0ejcugkgqgvh4e9.koreacentral-01.azurewebsites.net
```

### 7.2 ë°°í¬ëœ í•¨ìˆ˜ í—¬ìŠ¤ ì²´í¬

```bash
curl https://captcha-inference-app-f0ejcugkgqgvh4e9.koreacentral-01.azurewebsites.net/api/health

# ì‘ë‹µ:
# {
#   "status": "healthy",
#   "model_loaded": true,
#   "device": "cpu"
# }
```

### 7.3 ë°°í¬ëœ í•¨ìˆ˜ë¡œ ì¶”ë¡  í…ŒìŠ¤íŠ¸

```bash
curl -X POST https://captcha-inference-app-f0ejcugkgqgvh4e9.koreacentral-01.azurewebsites.net/api/InferenceHttpTrigger ^
  -F "image=@test_image.png"
```

---

## 8. API ì‚¬ìš© ê°€ì´ë“œ

### 8.1 ì—”ë“œí¬ì¸íŠ¸

| ì—”ë“œí¬ì¸íŠ¸ | ë©”ì„œë“œ | ì„¤ëª… |
|-----------|--------|------|
| `/api/InferenceHttpTrigger` | POST | ìº¡ì°¨ ì¸ì‹ |
| `/api/health` | GET | í—¬ìŠ¤ ì²´í¬ |

### 8.2 ìš”ì²­ í˜•ì‹

**URL**: `https://captcha-inference-app-f0ejcugkgqgvh4e9.koreacentral-01.azurewebsites.net/api/InferenceHttpTrigger`

**Method**: POST

**Content-Type**: multipart/form-data

**íŒŒë¼ë¯¸í„°**:
- Field name: `image`
- Field value: ì´ë¯¸ì§€ íŒŒì¼ (PNG, JPG, BMP)

### 8.3 cURL ì˜ˆì‹œ

```bash
curl -X POST ^
  "https://captcha-inference-app-f0ejcugkgqgvh4e9.koreacentral-01.azurewebsites.net/api/InferenceHttpTrigger" ^
  -F "image=@captcha.png"
```

### 8.4 Python ì˜ˆì‹œ

```python
import requests

url = "https://captcha-inference-app-f0ejcugkgqgvh4e9.koreacentral-01.azurewebsites.net/api/InferenceHttpTrigger"

with open("captcha.png", "rb") as f:
    files = {"image": f}
    response = requests.post(url, files=files)

result = response.json()
print(f"ì¸ì‹ ê²°ê³¼: {result['predicted_text']}")
print(f"ì‹ ë¢°ë„: {result['confidence']:.2%}")
```

### 8.5 JavaScript ì˜ˆì‹œ

```javascript
const formData = new FormData();
formData.append("image", imageFile);

const response = await fetch(
  "https://captcha-inference-app-f0ejcugkgqgvh4e9.koreacentral-01.azurewebsites.net/api/InferenceHttpTrigger",
  { method: "POST", body: formData }
);

const result = await response.json();
console.log(result);
```

### 8.6 ì‘ë‹µ í˜•ì‹

**ì„±ê³µ (HTTP 200)**:
```json
{
  "status": "success",
  "predicted_text": "ABCDEF",
  "confidence": 0.9523,
  "processing_time_ms": 145.2
}
```

**ì‹¤íŒ¨ (HTTP 400/500)**:
```json
{
  "status": "error",
  "message": "ì˜¤ë¥˜ ë©”ì‹œì§€"
}
```

---

## ğŸ“‹ ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸

```
[ ] Azure CLI ì„¤ì¹˜ ë° ë¡œê·¸ì¸ ì™„ë£Œ
[ ] Azure Functions Core Tools ì„¤ì¹˜ ì™„ë£Œ
[ ] PyCharm í”„ë¡œì íŠ¸ ìƒì„± ì™„ë£Œ
[ ] function_app.py ì½”ë“œ ì‘ì„± ì™„ë£Œ
[ ] requirements.txt ì‘ì„± ì™„ë£Œ
[ ] host.json ì‘ì„± ì™„ë£Œ
[ ] local.settings.json ì‘ì„± ì™„ë£Œ
[ ] model_best.pt íŒŒì¼ ë³µì‚¬ ì™„ë£Œ
[ ] ë¡œì»¬ í…ŒìŠ¤íŠ¸ ì„±ê³µ
[ ] Azure ë°°í¬ ì™„ë£Œ
[ ] í—¬ìŠ¤ ì²´í¬ ì„±ê³µ
[ ] API ì¶”ë¡  í…ŒìŠ¤íŠ¸ ì„±ê³µ
```

---

## ğŸ†˜ ë¬¸ì œ í•´ê²°

### "ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"

**í•´ê²°:**
1. PyCharmì—ì„œ `model/model_best.pt` íŒŒì¼ í™•ì¸
2. íŒŒì¼ì´ ì—†ìœ¼ë©´ ë³µì‚¬
3. ì¬ë°°í¬: `func azure functionapp publish captcha-inference-app`

### "Could not connect to the local Azure Function"

**í•´ê²°:**
```bash
# í¬íŠ¸ ì¶©ëŒ í™•ì¸
netstat -ano | findstr :7071

# ë‹¤ë¥¸ í¬íŠ¸ë¡œ ì‹¤í–‰
func start --port 7072
```

### "ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ModuleNotFoundError)"

**í•´ê²°:**
```bash
# ì˜ì¡´ì„± ì¬ì„¤ì¹˜
pip install --upgrade -r requirements.txt

# ìºì‹œ ì‚­ì œ í›„ ì¬ì„¤ì¹˜
pip cache purge
pip install -r requirements.txt
```

---

## ğŸ“ ì§€ì› ë¦¬ì†ŒìŠ¤

- [Azure Functions ë¬¸ì„œ](https://learn.microsoft.com/en-us/azure/azure-functions/)
- [Azure CLI ì°¸ê³ ì„œ](https://learn.microsoft.com/en-us/cli/azure/)
- [Azure Portal](https://portal.azure.com)

---

**ì¶•í•˜í•©ë‹ˆë‹¤! ì´ì œ Azure Function Appì—ì„œ ìº¡ì°¨ ì¸ì‹ APIë¥¼ ìš´ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!** ğŸ‰
